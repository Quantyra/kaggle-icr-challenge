{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223923c1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:38.227392Z",
     "iopub.status.busy": "2023-06-16T00:51:38.226756Z",
     "iopub.status.idle": "2023-06-16T00:51:38.241911Z",
     "shell.execute_reply": "2023-06-16T00:51:38.240462Z"
    },
    "papermill": {
     "duration": 0.025522,
     "end_time": "2023-06-16T00:51:38.244456",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.218934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\n",
      "/kaggle/input/icr-identify-age-related-conditions/greeks.csv\n",
      "/kaggle/input/icr-identify-age-related-conditions/train.csv\n",
      "/kaggle/input/icr-identify-age-related-conditions/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf30ca",
   "metadata": {
    "papermill": {
     "duration": 0.004605,
     "end_time": "2023-06-16T00:51:38.254140",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.249535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "This section contains the code to satisfy https://github.com/Quantyra/kaggle-ml-pipeline-icr-challenge/issues/5\n",
    "It processes and cleans the features, prepares them for use in the model.\n",
    "\n",
    "See https://www.kaggle.com/competitions/icr-identify-age-related-conditions/data for information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20293bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:38.266474Z",
     "iopub.status.busy": "2023-06-16T00:51:38.265692Z",
     "iopub.status.idle": "2023-06-16T00:51:38.272662Z",
     "shell.execute_reply": "2023-06-16T00:51:38.271711Z"
    },
    "papermill": {
     "duration": 0.015706,
     "end_time": "2023-06-16T00:51:38.275029",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.259323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracts the class column from the dataset and returns it. Then mutates the dataset by dropping the class column. Also ensures that Id column is completely unique and sets it as the index\n",
    "def extract_classes(dataset):\n",
    "    assert dataset['Id'].nunique() == dataset.shape[0]\n",
    "    dataset.index = dataset['Id']\n",
    "    dataset.drop(['Id'], axis='columns', inplace=True)\n",
    "    if 'Class' in dataset.columns:\n",
    "        y = dataset['Class']\n",
    "        dataset.drop(['Class'], axis='columns', inplace=True)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3130d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:38.286603Z",
     "iopub.status.busy": "2023-06-16T00:51:38.285873Z",
     "iopub.status.idle": "2023-06-16T00:51:38.292023Z",
     "shell.execute_reply": "2023-06-16T00:51:38.291132Z"
    },
    "papermill": {
     "duration": 0.014627,
     "end_time": "2023-06-16T00:51:38.294451",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.279824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some checks to ensure sanity of outputs after engineering\n",
    "def data_integrity_checks(dataset, classes, initial_row_count):\n",
    "    assert classes.name == 'Class'\n",
    "    assert classes.shape[0] == dataset.shape[0]\n",
    "    assert not dataset.isna().any().any() #No more nulls should be remaining as we converted them to zero\n",
    "    assert dataset.shape[0] == initial_row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8208537e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:38.306000Z",
     "iopub.status.busy": "2023-06-16T00:51:38.305384Z",
     "iopub.status.idle": "2023-06-16T00:51:38.311029Z",
     "shell.execute_reply": "2023-06-16T00:51:38.310230Z"
    },
    "papermill": {
     "duration": 0.013932,
     "end_time": "2023-06-16T00:51:38.313210",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.299278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encode the categorical values, but put an error check in place for the test set since it doesn't have the second class in the sample data.\n",
    "def encode_categories(dataset, column):\n",
    "    if dataset[column].nunique() > 1:\n",
    "        dataset[column] = pd.get_dummies(dataset[column], drop_first=True)\n",
    "    else:\n",
    "        dataset[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c52f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:38.324804Z",
     "iopub.status.busy": "2023-06-16T00:51:38.324182Z",
     "iopub.status.idle": "2023-06-16T00:51:38.330951Z",
     "shell.execute_reply": "2023-06-16T00:51:38.330145Z"
    },
    "papermill": {
     "duration": 0.015152,
     "end_time": "2023-06-16T00:51:38.333130",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.317978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mark rows that have null values with a binary flag, and reset null values to zeroes.\n",
    "def mark_missing_observations(dataset):\n",
    "    for column in dataset.columns:\n",
    "        new_columns = dataset[column].apply(lambda x: 1 if pd.isna(x) else 0)\n",
    "        new_columns.name = f\"{column}_missing\"\n",
    "        dataset = pd.concat([dataset, new_columns], axis='columns')\n",
    "        dataset[column] = dataset[column].fillna(0)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a980f6",
   "metadata": {
    "papermill": {
     "duration": 0.004299,
     "end_time": "2023-06-16T00:51:38.342212",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.337913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training set engineering\n",
    "\n",
    "We clean the training set by extracting the classes column, encoding the EJ column as a binary categorical value, and marking those rows/columns that have missing data while replacing null values with zero. Then we do some data integrity checks to ensure we have no null values and sane outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a87402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:38.353421Z",
     "iopub.status.busy": "2023-06-16T00:51:38.352817Z",
     "iopub.status.idle": "2023-06-16T00:51:38.926295Z",
     "shell.execute_reply": "2023-06-16T00:51:38.924903Z"
    },
    "papermill": {
     "duration": 0.582065,
     "end_time": "2023-06-16T00:51:38.928753",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.346688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Tables\n",
      "-----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 617 entries, 000ff2bfdfe9 to ffcca4ded3bb\n",
      "Columns: 112 entries, AB to GL_missing\n",
      "dtypes: float64(112)\n",
      "memory usage: 544.7+ KB\n",
      "None\n",
      "-----------\n",
      "               AB            AF           AH          AM          AR  \\\n",
      "count  617.000000    617.000000   617.000000  617.000000  617.000000   \n",
      "mean     0.477149   3502.013221   118.624513   38.968552   10.128242   \n",
      "std      0.468388   2300.322717   127.838950   69.728226   10.518877   \n",
      "min      0.081187    192.593280    85.200147    3.177522    8.138688   \n",
      "25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n",
      "50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n",
      "75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \n",
      "max      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n",
      "\n",
      "               AX          AY          AZ           BC           BD   ...  \\\n",
      "count  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \n",
      "mean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \n",
      "std      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \n",
      "min      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n",
      "25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n",
      "50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n",
      "75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \n",
      "max     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n",
      "\n",
      "       FI_missing  FL_missing  FR_missing  FS_missing  GB_missing  GE_missing  \\\n",
      "count       617.0  617.000000       617.0  617.000000       617.0       617.0   \n",
      "mean          0.0    0.001621         0.0    0.003241         0.0         0.0   \n",
      "std           0.0    0.040258         0.0    0.056888         0.0         0.0   \n",
      "min           0.0    0.000000         0.0    0.000000         0.0         0.0   \n",
      "25%           0.0    0.000000         0.0    0.000000         0.0         0.0   \n",
      "50%           0.0    0.000000         0.0    0.000000         0.0         0.0   \n",
      "75%           0.0    0.000000         0.0    0.000000         0.0         0.0   \n",
      "max           0.0    1.000000         0.0    1.000000         0.0         0.0   \n",
      "\n",
      "       GF_missing  GH_missing  GI_missing  GL_missing  \n",
      "count       617.0       617.0       617.0  617.000000  \n",
      "mean          0.0         0.0         0.0    0.001621  \n",
      "std           0.0         0.0         0.0    0.040258  \n",
      "min           0.0         0.0         0.0    0.000000  \n",
      "25%           0.0         0.0         0.0    0.000000  \n",
      "50%           0.0         0.0         0.0    0.000000  \n",
      "75%           0.0         0.0         0.0    0.000000  \n",
      "max           0.0         0.0         0.0    1.000000  \n",
      "\n",
      "[8 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "greeks_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')\n",
    "initial_row_count = train_df.shape[0]\n",
    "y_train = extract_classes(train_df)\n",
    "encode_categories(train_df, 'EJ')\n",
    "train_df = mark_missing_observations(train_df)\n",
    "train_df = train_df.astype(float)\n",
    "data_integrity_checks(train_df, y_train, initial_row_count)\n",
    "print('Summary Tables')\n",
    "print('-----------')\n",
    "print(train_df.info())\n",
    "print('-----------')\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a437a",
   "metadata": {
    "papermill": {
     "duration": 0.004647,
     "end_time": "2023-06-16T00:51:38.938562",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.933915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test dataset\n",
    "\n",
    "Upon notebook submission, the test dataset will be replaced by the full competition test dataset. This section of the notebook prepares the test data for use in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fdeb2ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:38.950511Z",
     "iopub.status.busy": "2023-06-16T00:51:38.949432Z",
     "iopub.status.idle": "2023-06-16T00:51:39.349269Z",
     "shell.execute_reply": "2023-06-16T00:51:39.347443Z"
    },
    "papermill": {
     "duration": 0.408312,
     "end_time": "2023-06-16T00:51:39.351641",
     "exception": false,
     "start_time": "2023-06-16T00:51:38.943329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Tables\n",
      "______________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, 00eed32682bb to 046e85c7cc7f\n",
      "Columns: 112 entries, AB to GL_missing\n",
      "dtypes: float64(112)\n",
      "memory usage: 4.4+ KB\n",
      "None\n",
      "______________\n",
      "        AB   AF   AH   AM   AR   AX   AY   AZ   BC  BD   ...  FI_missing  \\\n",
      "count  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  ...         5.0   \n",
      "mean   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
      "std    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
      "min    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
      "25%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
      "50%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
      "75%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
      "max    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
      "\n",
      "       FL_missing  FR_missing  FS_missing  GB_missing  GE_missing  GF_missing  \\\n",
      "count         5.0         5.0         5.0         5.0         5.0         5.0   \n",
      "mean          0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "std           0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "min           0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "25%           0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "50%           0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "75%           0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "max           0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "       GH_missing  GI_missing  GL_missing  \n",
      "count         5.0         5.0         5.0  \n",
      "mean          0.0         0.0         0.0  \n",
      "std           0.0         0.0         0.0  \n",
      "min           0.0         0.0         0.0  \n",
      "25%           0.0         0.0         0.0  \n",
      "50%           0.0         0.0         0.0  \n",
      "75%           0.0         0.0         0.0  \n",
      "max           0.0         0.0         0.0  \n",
      "\n",
      "[8 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "initial_row_count = test_df.shape[0]\n",
    "y_test = extract_classes(test_df)\n",
    "encode_categories(test_df, 'EJ')\n",
    "test_df = mark_missing_observations(test_df)\n",
    "test_df = test_df.astype(float)\n",
    "print(\"Summary Tables\")\n",
    "print(\"______________\")\n",
    "print(test_df.info())\n",
    "print(\"______________\")\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560f534",
   "metadata": {
    "papermill": {
     "duration": 0.006331,
     "end_time": "2023-06-16T00:51:39.363274",
     "exception": false,
     "start_time": "2023-06-16T00:51:39.356943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comparing Two CSV Files\n",
    "\n",
    "This section contains the code to satisfy https://github.com/Quantyra/kaggle-ml-pipeline-icr-challenge/issues/3. It takes two CSV files and compares them to see if the final submission is properly formatted to the sample_submission.csv file. The format must contain a header and follow the same format as the submission which includes three columns and two different data types (object, and float64).\n",
    "\n",
    "Sample Submission File:\n",
    "\n",
    "```\n",
    "Id,class_0,class_1\n",
    "00eed32682bb,0.5,0.5\n",
    "010ebe33f668,0.5,0.5\n",
    "02fa521e1838,0.5,0.5\n",
    "040e15f562a2,0.5,0.5\n",
    "046e85c7cc7f,0.5,0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefa679c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T00:51:39.375314Z",
     "iopub.status.busy": "2023-06-16T00:51:39.374872Z",
     "iopub.status.idle": "2023-06-16T00:51:39.382647Z",
     "shell.execute_reply": "2023-06-16T00:51:39.381506Z"
    },
    "papermill": {
     "duration": 0.016359,
     "end_time": "2023-06-16T00:51:39.384801",
     "exception": false,
     "start_time": "2023-06-16T00:51:39.368442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_csv_formats(file1, file2):\n",
    "    \"\"\"Compares the format of two CSV files using Pandas and returns a boolean.\n",
    "\n",
    "    Args:\n",
    "    file1: The path to the first CSV file.\n",
    "    file2: The path to the second CSV file.\n",
    "\n",
    "    Returns:\n",
    "    A boolean indicating whether the format of the two CSV files are identical.\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    if list(df1.columns) != list(df2.columns):\n",
    "        return False\n",
    "\n",
    "    if df1.shape[1] != df2.shape[1]:\n",
    "        return False\n",
    "\n",
    "    if not df1.dtypes.equals(df2.dtypes):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130f4a9",
   "metadata": {
    "papermill": {
     "duration": 0.004811,
     "end_time": "2023-06-16T00:51:39.394795",
     "exception": false,
     "start_time": "2023-06-16T00:51:39.389984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.468098,
   "end_time": "2023-06-16T00:51:40.222216",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-16T00:51:25.754118",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
